//helper functions
var countlist = function(n){
    var countdown = function(n){//So ugly! But if you're gonna use this as an index, it makes more sense/keeps correct correspondances in count-up order.
	if(n<=0) return [];
	return [n-1].concat(countdown(n-1));
    };
    countdown(n).reverse();
};
var max = function(arr){
    return reduce(function(a,b){if(a>b)return a; else return b;},arr[0],arr);
};
var hm_ppnts = max(map(function(arow){return arow.ppntid;},expdf))+1; //ASSUMING ids start from 0. Used to construct return values from mem-d functions by walking through a countlist of ppntids.

var recover_agentparams = function(){
    
    var  getmy_attributeAweight = mem(function(id){
	return 1; //Welcome to ABratio! Because all you care about is option ranks, you can express B in terms of scalefactor*Aweight and have the same model!
	//Assuming: A and B are coded such that higher numbers mean more likely to be chosen (probably it's possible to be unsure what the sign of an attribute should be... this model can't help you there?)
	//Also assuming A and B are independent, no interactions! That is definitely not true in general.
    });
    var  getmy_attributeBweight = mem(function(id){
	return modelParam({name:('ppntB_'+id),mu:1,sigma:5}); //Guide distribution, should be 'close' as you can get it, but not interpretable as a prior.
    });
    var getmy_calcsd = mem(function(id){
	return 4;
    });
    var getmy_tolerance_attributeA = mem(function(id){
	return 3;
    });
    var getmy_tolerance_attributeB= mem(function(id){
	return 3;
    });
    var getmy_orderr = mem(function(id){
	return 0.1;
    });

    var decision_distribution = function(arow){    
	var calc1 = gaussian({mu:arow.attributeA_option1*getmy_attributeAweight(arow.ppntid)+arow.attributeB_option1*getmy_attributeBweight(arow.ppntid),
			      sigma:getmy_calcsd(arow.ppntid)});
	var calc2 = gaussian({mu:arow.attributeA_option2*getmy_attributeAweight(arow.ppntid)+arow.attributeB_option2*getmy_attributeBweight(arow.ppntid),
			      sigma:getmy_calcsd(arow.ppntid)});
	var calc3 = gaussian({mu:arow.attributeA_option3*getmy_attributeAweight(arow.ppntid)+arow.attributeB_option3*getmy_attributeBweight(arow.ppntid),
			      sigma:getmy_calcsd(arow.ppntid)});
	
        var ordrelation = function(a,b,tolerance,orderr){//these args are individual values...
	    return Enumerate(function(){
		if(flip(orderr)) return categorical({vs:["<","=",">"],ps:[1,1,1]});
		if(Math.abs(a-b)<tolerance) return "=";
		if(a>b) return ">";
		if(a<b) return "<";
	    });
	}
	
	// var ordA_12 = sample(ordrelation(arow["attributeA_option1"],arow["attributeA_option2"],getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])));
	// var ordA_13 = sample(ordrelation(arow["attributeA_option1"],arow["attributeA_option3"],getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])));
	// var ordA_23 = sample(ordrelation(arow["attributeA_option2"],arow["attributeA_option3"],getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])));

	// var ordB_12 = sample(ordrelation(arow["attributeB_option1"],arow["attributeB_option2"],getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])));
	// var ordB_13 = sample(ordrelation(arow["attributeB_option1"],arow["attributeB_option3"],getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])));
	// var ordB_23 = sample(ordrelation(arow["attributeB_option2"],arow["attributeB_option3"],getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])));


	var agent = function(){
//	    var attributeAPrior =  Uniform({a:0,b:15});//true dist in manyppnts.csv
//	    var  attributeBPrior = Uniform({a:0,b:15});//is A:0-10,B:0-15

	    var my_A1 = modelParam({name:'my_A1',mu:5,sigma:5});//sample(attributeAPrior);
	    var my_A2 = modelParam({name:'my_A2',mu:5,sigma:5});//sample(attributeAPrior);
	    var my_A3 = modelParam({name:'my_A3',mu:5,sigma:5});//sample(attributeAPrior);
	    var my_B1 = modelParam({name:'my_B1',mu:5,sigma:5});//sample(attributeBPrior);
	    var my_B2 = modelParam({name:'my_B2',mu:5,sigma:5});//sample(attributeBPrior);
	    var my_B3 = modelParam({name:'my_B3',mu:5,sigma:5});//sample(attributeBPrior);

	    observe(Gaussian({mu:my_A1*getmy_attributeAweight(arow.ppntid)+my_B1*getmy_attributeBweight(arow.ppntid),sigma:getmy_calcsd(arow.ppntid)}),calc1);
	    observe(Gaussian({mu:my_A2*getmy_attributeAweight(arow.ppntid)+my_B2*getmy_attributeBweight(arow.ppntid),sigma:getmy_calcsd(arow.ppntid)}),calc2);
	    observe(Gaussian({mu:my_A3*getmy_attributeAweight(arow.ppntid)+my_B3*getmy_attributeBweight(arow.ppntid),sigma:getmy_calcsd(arow.ppntid)}),calc3);

    	    // observe(ordrelation(my_A1,my_A2,getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordA_12);
	    // observe(ordrelation(my_A1,my_A3,getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordA_13);
	    // observe(ordrelation(my_A2,my_A3,getmy_tolerance_attributeA(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordA_23);
	    // observe(ordrelation(my_B1,my_B2,getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordB_12);
	    // observe(ordrelation(my_B1,my_B3,getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordB_13);
	    // observe(ordrelation(my_B2,my_B3,getmy_tolerance_attributeB(arow["ppntid"]),getmy_orderr(arow["ppntid"])),ordB_23);
	    
	    var opt1 = my_A1*getmy_attributeAweight(arow.ppntid)+ my_B1*getmy_attributeBweight(arow.ppntid);
	    var opt2 = my_A2*getmy_attributeAweight(arow.ppntid)+ my_B2*getmy_attributeBweight(arow.ppntid);
	    var opt3 = my_A3*getmy_attributeAweight(arow.ppntid)+ my_B3*getmy_attributeBweight(arow.ppntid);
	    
	    return "ret value not useful with optimize?"//[opt1,opt2,opt3];
	};//end agent function

	Optimize({model: agent, steps: 100, optMethod:{adam:{stepSize:.1}}});



	var opt1 = getParams().my_A1*getmy_attributeAweight(arow["ppntid"])+ getParams().my_B1*getmy_attributeBweight(arow["ppntid"]);
	var opt2 = getParams().my_A2*getmy_attributeAweight(arow["ppntid"])+ getParams().my_B2*getmy_attributeBweight(arow["ppntid"]);
	var opt3 = getParams().my_A3*getmy_attributeAweight(arow["ppntid"])+ getParams().my_B3*getmy_attributeBweight(arow["ppntid"]);

	var retval = (opt1>opt2&&opt1>opt3 ? 1 : opt2>opt1&&opt2>opt3 ? 2 : 3);
	
	return 	Categorical({vs:[1,2,3,retval],ps:[5/3,5/3,5/3,95]});
	//UGH. Here's how this ugly monster came to be:
	// retval is an int, you could just return that. But there's no uncertainty associated with it so condition(choice==retval) kills ELBO if retval is ever !=choice. So dead.
	//It seems natural to make this a distribution, with choice probs opt[i]/(sum_opts), to give some sensible level of support to all options.
	//The problem with *that* is that anything that touches a param becomes a Node object, which can't be used in ps. Node objects can talk to each other, so the calculation of retval behaves like you'd expect and returns and int, but you cant have  opt[i]/(sum_opts) in ps.
	//So, this unloveable hack gives support to all choices, but strongly favors opt_agent's choice, whatever that is.
	
    };//end decision_distribution(arow)

    var obsfunction = function(arow){
	observe(decision_distribution(arow),arow.choice);
    };//end obsfunction

    mapData({data:expdf},obsfunction);//opt uses mapData rather than map 'where possible'. Is this possible, or should it be applied over participant-level chunks? Requirement is 'conditional independence', ppnts are independent, obs from the same ppnt not, unless the 'conditional' part means 'conditional on the modelParams'. RESOLVE THIS.

    // var ret =  map(function(x){return [x, getmy_attributeBweight(x)]},countlist(hm_ppnts));
    // return ret;
}



Optimize({model:recover_agentparams,steps:500,optMethod:{adam:{stepSize:.1}}});//more steps is better... up to convergence. Which probably happens in the mid hundreds, but check? 

//return value:
map(function(x){return getParams()[('ppntB_'+x)]},countlist(hm_ppnts))
